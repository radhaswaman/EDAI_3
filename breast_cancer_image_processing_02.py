# -*- coding: utf-8 -*-
"""Breast Cancer Image Processing_02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v7PRe2tglVyib31bOOkf-G-lvtVGzF-V
"""

import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/gdrive')

dataset_path = "/content/gdrive/MyDrive/Dataset_BUSI_with_GT"

import tensorflow as tf
ds_train = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(256, 256),
    batch_size=32
)

ds_validation = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(256, 256),
    batch_size=32
)

def merge_labels(x, y):

    y = tf.where(y == 1, 1, 0)  # malignant becomes 1, benign and normal become 0
    return x, y

# Apply the label merging to both training and validation datasets
ds_train = ds_train.map(merge_labels)
ds_validation = ds_validation.map(merge_labels)

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.2),
    layers.RandomContrast(0.2)
])

normalization_layer = layers.Rescaling(1./255)

ds_train = ds_train.map(lambda x, y: (data_augmentation(normalization_layer(x)), y))
ds_validation = ds_validation.map(lambda x, y: (normalization_layer(x), y))

# Prefetching data for better performance
ds_train = ds_train.prefetch(buffer_size=tf.data.AUTOTUNE)
ds_validation = ds_validation.prefetch(buffer_size=tf.data.AUTOTUNE)

# Building the model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.5),  # Dropout to reduce overfitting
    layers.Dense(1, activation='sigmoid')  # Binary classification: benign/normal (0) or malignant (1)
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Callbacks for Early Stopping and saving the best model
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.keras', save_best_only=True)

# Train the model
history = model.fit(
    ds_train,
    validation_data=ds_validation,
    epochs=20,
    callbacks=[early_stopping, model_checkpoint]
)

# Plot the training history
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

val_loss, val_acc = model.evaluate(ds_validation)
print(f"Validation Accuracy: {val_acc * 100:.2f}%")

# Save the entire model to a file
model.save('final_model.h5')

import matplotlib.pyplot as plt

# Function to display images from a dataset
def display_images_from_dataset(dataset, num_images=9):
    plt.figure(figsize=(10, 10))

    for images, labels in dataset.take(1):
        for i in range(num_images):
            ax = plt.subplot(3, 3, i + 1)
            img = images[i].numpy()
            img = (img * 255).astype("uint8")
            plt.imshow(img)
            plt.title("Malignant" if labels[i] == 1 else "Benign")
            plt.axis("off")

    plt.show()

# Display images from the training dataset
display_images_from_dataset(ds_train)

display_images_from_dataset(ds_validation)

#MODEL EVALUATION

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.preprocessing import image

model = tf.keras.models.load_model('final_model.h5')

new_images_path = '/content/gdrive/MyDrive/Predict_Images'

def load_and_preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(256, 256))
    img_array = image.img_to_array(img)
    img_array = img_array / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    return img_array

def predict_and_visualize(image_paths):
    plt.figure(figsize=(12, 12))

    for i, img_path in enumerate(image_paths):
        img_array = load_and_preprocess_image(img_path)
        predictions = model.predict(img_array)
        predicted_class = np.round(predictions[0][0])

        # Load and display the image
        img = image.load_img(img_path, target_size=(256, 256))
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(img)
        plt.title("Prediction: Malignant" if predicted_class == 1 else "Prediction: Benign")
        plt.axis("off")

    plt.show()

new_image_paths = [

   '/content/gdrive/MyDrive/Predict_Images/malignant (137)_mask.png',
   '/content/gdrive/MyDrive/Predict_Images/benign (145)_mask.png',
   '/content/gdrive/MyDrive/Predict_Images/benign (145).png',




]

# Predict and visualize
predict_and_visualize(new_image_paths)